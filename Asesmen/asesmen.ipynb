{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import pandas as pd\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict skin type\n",
    "def predict_skin_type(file_path, tflite_model_path):\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    img = image.load_img(file_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0).astype(np.float32)\n",
    "\n",
    "    # Manage input and output\n",
    "    input_index = interpreter.get_input_details()[0]['index']\n",
    "    output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "    # Inference\n",
    "    interpreter.set_tensor(input_index, img_array)\n",
    "    interpreter.invoke()\n",
    "    predictions = interpreter.get_tensor(output_index)\n",
    "\n",
    "    # Mapping results to classes\n",
    "    class_names = ['Berjerawat', 'Berminyak', 'Kering', 'Normal']\n",
    "    predicted_class = np.argmax(predictions)\n",
    "    return class_names[predicted_class]\n",
    "\n",
    "# Remove punctuation for string matching\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Levenshtein\n",
    "def levenshtein_distance(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    previous_row = list(range(len(s2) + 1))\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]\n",
    "\n",
    "# The dataset used is product_assessment, for string matching only use ingredients\n",
    "df = pd.read_csv('./product_asesmen.csv')\n",
    "df['ingredients'] = df['ingredients'].fillna('').astype(str)\n",
    "\n",
    "dataset_ingredients = set(\n",
    "    remove_punctuation(word.strip()).lower()\n",
    "    for ing in df['ingredients']\n",
    "    for word in ing.split(',')\n",
    ")\n",
    "\n",
    "# Correcting ingredients entered by the user\n",
    "def koreksi_ingredients(input_string, dataset_ingredients, threshold=1):\n",
    "    if not input_string:\n",
    "        return []\n",
    "\n",
    "    corrected_ingredients = []\n",
    "    strings_to_check = [\n",
    "        remove_punctuation(word.strip()).lower() for word in input_string.split(',')\n",
    "    ]\n",
    "\n",
    "    for string_to_check in strings_to_check:\n",
    "        if string_to_check in dataset_ingredients:\n",
    "            corrected_ingredients.append(string_to_check)\n",
    "        else:\n",
    "            closest_match = None\n",
    "            closest_distance = float('inf')\n",
    "\n",
    "            for candidate in dataset_ingredients:\n",
    "                distance = levenshtein_distance(string_to_check, candidate)\n",
    "                if distance < closest_distance:\n",
    "                    closest_distance = distance\n",
    "                    closest_match = candidate\n",
    "\n",
    "            if closest_distance <= threshold:\n",
    "                corrected_ingredients.append(closest_match)\n",
    "\n",
    "    return corrected_ingredients\n",
    "\n",
    "# Product recommendations according to assessment\n",
    "def recommended_product(kriteria, predicted_skin_type):\n",
    "    sensitif = kriteria[0]\n",
    "    tujuan = kriteria[1]\n",
    "    fungsi = kriteria[2]\n",
    "    hamil_menyusui = kriteria[3]\n",
    "    ingredients = kriteria[4]\n",
    "\n",
    "    # If the answer value for index 0 or sensitive is 'a' then sensitive skin type is also included in the filter\n",
    "    if sensitif == 'a':\n",
    "        jenis_kulit_list = [predicted_skin_type, 'Sensitif']\n",
    "    else:\n",
    "        jenis_kulit_list = [predicted_skin_type]  # If the value is not 'a' but 'b' then the skin type matches predicted_skin_type\n",
    "\n",
    "    # Process ingredients if there is input from the user\n",
    "    if ingredients and str(ingredients).lower() not in ['none', 'nan', '']:\n",
    "        if isinstance(ingredients, list):\n",
    "            corrected_ingredients = [\n",
    "                koreksi_ingredients(ing, dataset_ingredients) for ing in ingredients\n",
    "            ]\n",
    "            corrected_ingredients = [item for sublist in corrected_ingredients for item in sublist]\n",
    "        else:\n",
    "            corrected_ingredients = koreksi_ingredients(ingredients, dataset_ingredients)\n",
    "\n",
    "        corrected_ingredients_str = '|'.join(corrected_ingredients)\n",
    "\n",
    "        if corrected_ingredients:\n",
    "            produk = df[\n",
    "                (df['jenis_kulit'].isin(jenis_kulit_list)) &\n",
    "                (df['tujuan'] == tujuan) &\n",
    "                (df['fungsi'].apply(lambda x: all(f in str(x).split(',') for f in fungsi))) &\n",
    "                (df['hamil_menyusui'] == hamil_menyusui) &\n",
    "                (~df['ingredients'].str.contains(corrected_ingredients_str, case=False, na=False))\n",
    "            ]\n",
    "        else:\n",
    "            produk = df[\n",
    "                (df['jenis_kulit'].isin(jenis_kulit_list)) &\n",
    "                (df['tujuan'] == tujuan) &\n",
    "                (df['fungsi'].apply(lambda x: all(f in str(x).split(',') for f in fungsi))) &\n",
    "                (df['hamil_menyusui'] == hamil_menyusui)\n",
    "            ]\n",
    "    else:\n",
    "        produk = df[\n",
    "            (df['jenis_kulit'].isin(jenis_kulit_list)) &\n",
    "            (df['tujuan'] == tujuan) &\n",
    "            (df['fungsi'].apply(lambda x: all(f in str(x).split(',') for f in fungsi))) &\n",
    "            (df['hamil_menyusui'] == hamil_menyusui)\n",
    "        ]\n",
    "\n",
    "    return produk['nama_product'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2% Salicylic Acid BHA Acne Spot Treatment', 'Aloe Soothing Sun Cream']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        file_path = './test_image.png'\n",
    "        predicted_skin_type = predict_skin_type(file_path, 'skintype_model.tflite')\n",
    "        if predicted_skin_type:\n",
    "            input_asesmen = ['a', 'b', ['b', 'f'], 'a', []]\n",
    "            product = recommended_product(input_asesmen, predicted_skin_type)\n",
    "            print(product)\n",
    "        else:\n",
    "            print(\"Skintype prediction failed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
